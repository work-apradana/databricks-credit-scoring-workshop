{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e58d2274-d22a-421a-8167-1ed3428b56a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# 5. Data Governance\n",
    "\n",
    "## Notebook Description\n",
    "\n",
    "This notebook demonstrates the data governance capabilities of Unity Catalog in Databricks. It showcases how to document tables and columns, manage metadata, and improve data discoverability and compliance using AI-generated comments and structured schema information.\n",
    "\n",
    "Sections:\n",
    "- Access Control\n",
    "- Column Masking\n",
    "- Row Filter\n",
    "- Data Lineage\n",
    "- AI-generated comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG = 'workspace'\n",
    "BRONZE_SCHEMA = 'bronze'\n",
    "SILVER_SCHEMA = 'silver'\n",
    "GOLD_SCHEMA   = 'gold'\n",
    "\n",
    "GROUP_NAME = 'analysts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25dae1ae-5d8e-43eb-867c-9cdb4743edd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 1. Access control\n",
    "\n",
    "In the Lakehouse, you can use simple SQL GRANT and REVOKE statements to create granular (on data and even schema and catalog levels) access control irrespective of the data source or format.\n",
    "\n",
    "To run this Access Control demo, you will need to create a `group`. You can go to your avatar at the top-right corner of the Databricks UI, click on it then navigate to \"Settings\" > \"Identity and access\" > \"Groups\" > click \"Manage\" > click \"Add group\" > \"Add new\" > Enter a name for the group.\n",
    "\n",
    "*Note that in Databricks Free Edition, this Access control demo will not run well since you cannot create a group in Free Edition.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a9e9ffc-c91e-4c0b-89a1-b7b5ef411e0e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Grant Access Control"
    }
   },
   "outputs": [],
   "source": [
    "# Let's grant our ANALYSTS a SELECT permission:\n",
    "# Note: make sure you created an `analysts` group first.\n",
    "display(spark.sql(f\"GRANT SELECT ON TABLE {CATALOG}.{GOLD_SCHEMA}.applicants TO `{GROUP_NAME}`\"))\n",
    "\n",
    "# We'll grant an extra MODIFY to our Data Engineer\n",
    "display(spark.sql(f\"GRANT SELECT, MODIFY ON TABLE {CATALOG}.{GOLD_SCHEMA}.applicants TO `{GROUP_NAME}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca7048e9-fd9e-4fe5-9e34-e5db9d5b84fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check the permissions for the analysts group\n",
    "display(spark.sql(f\"SHOW GRANTS ON TABLE {CATALOG}.{GOLD_SCHEMA}.applicants\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "114798ad-af5d-44b7-855c-3c94dafa36fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now let's try removing grants\n",
    "display(spark.sql(f\"REVOKE SELECT, MODIFY ON TABLE {CATALOG}.{GOLD_SCHEMA}.applicants FROM `{GROUP_NAME}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b66a57b-f10d-4cab-a768-393e053cb9f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check that `analysts` group does not have any permissions anymore\n",
    "display(spark.sql(f\"SHOW GRANTS ON TABLE {CATALOG}.{GOLD_SCHEMA}.applicants\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "003ced51-a44a-4ed7-87ba-2e228c086ad3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Row and Column-level masking\n",
    "\n",
    "There are 2 ways to do masking, using Dynamic View and Row Filter / Column Mask functions.\n",
    "\n",
    "**Dynamic View masking** uses SQL logic (e.g., CASE statements) within views to redact or transform column values based on user/group membership. It is managed at the view level and is flexible for simple access scenarios.\n",
    "\n",
    "**Row Filter / Column Mask Functions** leverages UDF function to filter rows or to mask column containing sensitive information. User can combine this with Unity Catalog attribute-based access control policy to centrally manage column masks using governed tags. Policies are applied at the catalog/schema/table level, enabling scalable, consistent, and auditable masking across multiple tables based on user attributes and data classification.\n",
    "\n",
    "**Summary:** Dynamic Views are suitable for custom, table-specific masking, while Row Filter & Column Mask with ABAC Policy provide centralized, tag-driven governance for sensitive data masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bab39b05-8f6d-456e-883d-fe6513fa824d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 2. Row/Column-level masking using Dynamic View\n",
    "\n",
    "In the cells below we will demonstrate how to handle sensitive data through column masking using Dynamic View method.\n",
    "\n",
    "Table: `{CATALOG}.{GOLD_SCHEMA}.applicants`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2321eb0-8fa2-47e8-adb2-984bd4fcbbbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a secured view for applicants by masking KTP number\n",
    "display(spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE VIEW {CATALOG}.{SILVER_SCHEMA}.applicants_secured AS\n",
    "SELECT\n",
    "  c.* EXCEPT (ktp_number),\n",
    "  CASE\n",
    "    WHEN is_member('users')\n",
    "      THEN '*********'\n",
    "    ELSE CAST(c.ktp_number AS STRING)\n",
    "  END AS ktp_number_protected\n",
    "FROM\n",
    "  {CATALOG}.{SILVER_SCHEMA}.applicants AS c;\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1770ca0-a424-477d-ad3b-a0521f320aa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if the view really masks KTP number\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  applicant_id,\n",
    "  nama_lengkap,\n",
    "  jenis_kelamin,\n",
    "  ktp_number_protected\n",
    "FROM {CATALOG}.{SILVER_SCHEMA}.applicants_secured\n",
    "LIMIT 5;\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d7eb8f5-b054-4cb7-a7ef-79820f9a24fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 3. Row/Column-level masking using UDF Functions\n",
    "\n",
    "In the cells below we will demonstrate how to handle sensitive data through column masking using UDF Functions.\n",
    "\n",
    "_Note that this can be combined further with ABAC Policy to mask based on certain attributes but it is out of scope of this notebook for now_.\n",
    "\n",
    "Table: `{CATALOG}.{GOLD_SCHEMA}.applicants`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9987abf-ad34-4109-b8d5-85a662461685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create column mask functions\n",
    "display(spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION ktp_mask(ktp_number STRING)\n",
    "  RETURN \n",
    "    CASE \n",
    "      WHEN is_account_group_member('users') THEN ktp_number \n",
    "      ELSE '******' \n",
    "    END;\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94a2a690-0bd0-413c-a692-64bdce225220",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply column mask functions to table\n",
    "display(spark.sql(f\"\"\"\n",
    "ALTER TABLE {CATALOG}.{SILVER_SCHEMA}.applicants ALTER COLUMN ktp_number SET MASK ktp_mask;\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb77329-d68e-491f-b3ff-1d7dd39f326e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if the view really masks KTP number\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  applicant_id,\n",
    "  nama_lengkap,\n",
    "  jenis_kelamin,\n",
    "  ktp_number\n",
    "FROM {CATALOG}.{SILVER_SCHEMA}.applicants\n",
    "LIMIT 5;\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c52d992-09af-4fd0-b733-8a8037b0a57e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up\n",
    "display(spark.sql(f\"ALTER TABLE {CATALOG}.{SILVER_SCHEMA}.applicants ALTER COLUMN ktp_number DROP MASK;\"))\n",
    "display(spark.sql(f\"DROP FUNCTION ktp_mask;\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7bf8a30-db7b-46ad-b864-b9e3f64cdb13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Step 4. Data Lineage\n",
    "\n",
    "Lineage is critical for understanding compliance, audit, observability, but also discoverability of data.\n",
    "\n",
    "These are three very common schenarios, where full data lineage becomes incredibly important:\n",
    "1. **Explainability** - we need to have the means of tracing features used in machine learning to the raw data that created those features,\n",
    "2. Tracing **missing values** in a dashboard or ML model to the origin,\n",
    "3. **Finding specific data** - organizations have hundreds and even thousands of data tables and sources. Finiding the table or column that contains specific information can be daunting without a proper discoverability tools.\n",
    "\n",
    "**Note**: To explore the lineage, navigate to the Catalog, and find the ```{CATALOG}.{GOLD_SCHEMA}.applicants``` table inside your catalog and schema, then click the `Lineage` tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47a43614-05ed-4a2e-84f4-4fe494fdef0f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "AI-Generated Comments Demo"
    }
   },
   "source": [
    "## Step 5. AI-Generated Comments for Data Governance\n",
    "\n",
    "Comments are useful for several purposes:\n",
    "* For Data Discovery: Users can find tables and columns by description\n",
    "* For Data Dictionary: Column and table meanings are clearly described thus providing context for users and AI alike.\n",
    "* For Governance: Supports context for data lineage and documentation audit\n",
    "* For Documentation: consistent semantics, meaning, duplicate data creation hence increasing quality of data\n",
    "\n",
    "Aside from using SQL command, we can also generate comments and descriptions from Catalog Explorer.\n",
    "\n",
    "**Table:** `{CATALOG}.{GOLD_SCHEMA}.loans`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd987f0-9aaa-404c-a26a-25ecc445025d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add AI-generated column comments"
    }
   },
   "outputs": [],
   "source": [
    "# Add descriptive comments to each column\n",
    "# These help users understand the data without reading documentation\n",
    "\n",
    "display(spark.sql(f\"\"\"\n",
    "ALTER TABLE {CATALOG}.{GOLD_SCHEMA}.loans ALTER COLUMN loan_id \n",
    "COMMENT 'Unique identifier for each loan record';\n",
    "\"\"\"))\n",
    "\n",
    "# Add comprehensive table description\n",
    "display(spark.sql(f\"\"\"\n",
    "COMMENT ON TABLE {CATALOG}.{GOLD_SCHEMA}.loans IS \n",
    "'Gold-layer table containing loan transaction records with terms, amounts, and default status. \n",
    "Used for credit risk analysis and loan portfolio management. \n",
    "Joins with applicants table via applicant_id.';\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a3938e0-4dbe-4a00-a74b-3ac59d1ae1ce",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View documented schema"
    }
   },
   "outputs": [],
   "source": [
    "# Query to see all column comments\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  column_name,\n",
    "  data_type,\n",
    "  comment\n",
    "FROM {CATALOG}.information_schema.columns\n",
    "WHERE \n",
    "  table_catalog = '{CATALOG}'\n",
    "  AND table_schema = '{GOLD_SCHEMA}'\n",
    "  AND table_name = 'loans'\n",
    "ORDER BY ordinal_position\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6224717010893983,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "05-Data-Governance",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
